{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FX Predicter V2 (Trading-Oriented)\n",
    "\n",
    "\u042d\u0442\u043e\u0442 \u043d\u043e\u0443\u0442\u0431\u0443\u043a \u0440\u0430\u0437\u0431\u0438\u0442 \u043d\u0430 \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u044d\u0442\u0430\u043f\u044b:\n",
    "1. \u041a\u043e\u043d\u0444\u0438\u0433 \u0438 \u0438\u043c\u043f\u043e\u0440\u0442\u044b\n",
    "2. \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n",
    "3. \u0424\u0438\u0447\u0438 \u0438 \u0442\u0430\u0440\u0433\u0435\u0442\u044b\n",
    "4. \u041e\u043a\u043d\u0430 \u0438 \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\n",
    "5. \u0410\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u043c\u043e\u0434\u0435\u043b\u0438\n",
    "6. \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n",
    "7. \u041f\u043e\u0434\u0431\u043e\u0440 \u0442\u043e\u0440\u0433\u043e\u0432\u044b\u0445 \u043f\u043e\u0440\u043e\u0433\u043e\u0432 \u043d\u0430 validation\n",
    "8. \u0424\u0438\u043d\u0430\u043b\u044c\u043d\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043d\u0430 test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data_path: str = \"/Users/data/VsCodeProjects/DataScience/data/raw/eurusd_hour.csv\"\n",
    "    window_len: int = 72\n",
    "\n",
    "    spread_cost: float = 0.00003\n",
    "    slippage_cost: float = 0.00001\n",
    "    min_edge_buffer: float = 0.00002\n",
    "\n",
    "    train_ratio: float = 0.70\n",
    "    val_ratio: float = 0.15\n",
    "\n",
    "    epochs: int = 80\n",
    "    batch_size: int = 64\n",
    "    seed: int = 42\n",
    "\n",
    "cfg = Config()\n",
    "tf.keras.utils.set_random_seed(cfg.seed)\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438 \u0431\u0430\u0437\u043e\u0432\u0430\u044f \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_dataframe(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"]).dt.time\n",
    "    df[\"Datetime\"] = df.apply(lambda row: pd.Timestamp.combine(row[\"Date\"], row[\"Time\"]), axis=1)\n",
    "\n",
    "    df.index = pd.to_datetime(df[\"Datetime\"])\n",
    "    df = df.drop(columns=[\"Datetime\", \"Date\", \"Time\"])\n",
    "\n",
    "    df[\"Price_open\"] = df[[\"BO\", \"AO\"]].mean(axis=1)\n",
    "    df[\"Highest\"] = df[[\"BH\", \"AH\"]].mean(axis=1)\n",
    "    df[\"Lowest\"] = df[[\"BL\", \"AL\"]].mean(axis=1)\n",
    "    df[\"Price_close\"] = df[[\"BC\", \"AC\"]].mean(axis=1)\n",
    "    df[\"change\"] = df[[\"BCh\", \"ACh\"]].mean(axis=1)\n",
    "\n",
    "    df = df.drop(columns=[\"BO\", \"AO\", \"BH\", \"AH\", \"BL\", \"AL\", \"BC\", \"AC\", \"BCh\", \"ACh\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_base_dataframe(cfg.data_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"hour_sin\"] = np.sin(2 * np.pi * out.index.hour / 24)\n",
    "    out[\"hour_cos\"] = np.cos(2 * np.pi * out.index.hour / 24)\n",
    "\n",
    "    out[\"log_ret_body\"] = np.log(out[\"Price_close\"] / out[\"Price_open\"])\n",
    "    out[\"range\"] = (out[\"Highest\"] - out[\"Lowest\"]) / out[\"Price_open\"]\n",
    "    out[\"upper_wick\"] = (out[\"Highest\"] - out[[\"Price_open\", \"Price_close\"]].max(axis=1)) / out[\"Price_open\"]\n",
    "    out[\"lower_wick\"] = (out[[\"Price_open\", \"Price_close\"]].min(axis=1) - out[\"Lowest\"]) / out[\"Price_open\"]\n",
    "    out[\"close_pos\"] = (out[\"Price_close\"] - out[\"Lowest\"]) / (out[\"Highest\"] - out[\"Lowest\"])\n",
    "\n",
    "    asia_open, asia_close = 2, 10\n",
    "    frankfurt_open, frankfurt_close = 10, 11\n",
    "    london_open, london_close = 11, 19\n",
    "    ny_open, ny_close = 16, 0\n",
    "\n",
    "    out[\"is_asia\"] = ((out.index.hour >= asia_open) & (out.index.hour <= asia_close)).astype(int)\n",
    "    out[\"is_frankfurt\"] = ((out.index.hour >= frankfurt_open) & (out.index.hour <= frankfurt_close)).astype(int)\n",
    "    out[\"is_london\"] = ((out.index.hour >= london_open) & (out.index.hour <= london_close)).astype(int)\n",
    "    out[\"is_ny\"] = ((out.index.hour >= ny_open) | (out.index.hour <= ny_close)).astype(int)\n",
    "\n",
    "    f_change = out[\"is_frankfurt\"].diff().abs() > 0\n",
    "    l_change = out[\"is_london\"].diff().abs() > 0\n",
    "    n_change = out[\"is_ny\"].diff().abs() > 0\n",
    "    out[\"if_change\"] = (f_change | l_change | n_change).astype(int)\n",
    "\n",
    "    for i in [3, 6, 12]:\n",
    "        out[f\"mom_{i}\"] = out[\"log_ret_body\"].rolling(i).sum()\n",
    "        out[f\"vol_{i}\"] = out[\"log_ret_body\"].rolling(i).std()\n",
    "\n",
    "    for i in [3, 6]:\n",
    "        out[f\"pressure_{i}\"] = out[\"close_pos\"].rolling(i).mean()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "df = add_features(df)\n",
    "print(df.shape)\n",
    "df.tail(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Targets \u0434\u043b\u044f \u0442\u043e\u0440\u0433\u043e\u0432\u043b\u0438\n",
    "\n",
    "- `target_delta`: \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f \u0434\u0432\u0438\u0436\u0435\u043d\u0438\u044f \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u0431\u0430\u0440\u0430\n",
    "- `target_dir`: \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f\n",
    "- `target_quality`: \u0435\u0441\u0442\u044c \u043b\u0438 edge \u043f\u043e\u0441\u043b\u0435 costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_targets(df: pd.DataFrame, cfg: Config) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    total_cost = cfg.spread_cost + cfg.slippage_cost + cfg.min_edge_buffer\n",
    "\n",
    "    out[\"target_delta\"] = np.log(out[\"Price_close\"].shift(-1) / out[\"Price_close\"])\n",
    "    out[\"target_dir\"] = (out[\"target_delta\"] > 0).astype(int)\n",
    "    out[\"target_quality\"] = (out[\"target_delta\"].abs() > total_cost).astype(int)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "df = add_targets(df, cfg)\n",
    "\n",
    "excluded = [\n",
    "    \"Price_open\", \"Price_close\", \"Highest\", \"Lowest\", \"change\",\n",
    "    \"target_delta\", \"target_dir\", \"target_quality\"\n",
    "]\n",
    "features = [c for c in df.columns if c not in excluded]\n",
    "\n",
    "df = df.dropna(subset=features + [\"target_delta\", \"target_dir\", \"target_quality\"]).copy()\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Num features:\", len(features))\n",
    "print(\"target_dir mean:\", float(df[\"target_dir\"].mean()))\n",
    "print(\"target_quality mean:\", float(df[\"target_quality\"].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) \u041e\u043a\u043d\u0430 \u0438 \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(df: pd.DataFrame, features: list[str], cfg: Config):\n",
    "    X_all = df[features].values\n",
    "    y_delta = df[\"target_delta\"].values\n",
    "    y_dir = df[\"target_dir\"].values\n",
    "    y_quality = df[\"target_quality\"].values\n",
    "\n",
    "    X, y_d, y_c, y_q, target_idx = [], [], [], [], []\n",
    "    for i in range(len(df) - cfg.window_len):\n",
    "        j = i + cfg.window_len\n",
    "        X.append(X_all[i : j])\n",
    "        y_d.append(y_delta[j])\n",
    "        y_c.append(y_dir[j])\n",
    "        y_q.append(y_quality[j])\n",
    "        target_idx.append(j)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y_d = np.array(y_d).reshape(-1, 1)\n",
    "    y_c = np.array(y_c).reshape(-1, 1)\n",
    "    y_q = np.array(y_q).reshape(-1, 1)\n",
    "    target_idx = np.array(target_idx)\n",
    "\n",
    "    train_size = int(len(X) * cfg.train_ratio)\n",
    "    val_size = int(len(X) * cfg.val_ratio)\n",
    "\n",
    "    X_train = X[:train_size]\n",
    "    X_val = X[train_size : train_size + val_size]\n",
    "    X_test = X[train_size + val_size :]\n",
    "\n",
    "    y_train = [y_d[:train_size], y_c[:train_size], y_q[:train_size]]\n",
    "    y_val = [\n",
    "        y_d[train_size : train_size + val_size],\n",
    "        y_c[train_size : train_size + val_size],\n",
    "        y_q[train_size : train_size + val_size],\n",
    "    ]\n",
    "    y_test = [y_d[train_size + val_size :], y_c[train_size + val_size :], y_q[train_size + val_size :]]\n",
    "\n",
    "    idx_train = target_idx[:train_size]\n",
    "    idx_val = target_idx[train_size : train_size + val_size]\n",
    "    idx_test = target_idx[train_size + val_size :]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, idx_train, idx_val, idx_test\n",
    "\n",
    "\n",
    "def scale_windows(X_train: np.ndarray, X_val: np.ndarray, X_test: np.ndarray):\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X_train.reshape(-1, X_train.shape[-1]))\n",
    "\n",
    "    def apply(x: np.ndarray) -> np.ndarray:\n",
    "        x_2d = x.reshape(-1, x.shape[-1])\n",
    "        x_scaled = scaler.transform(x_2d)\n",
    "        return x_scaled.reshape(x.shape)\n",
    "\n",
    "    return apply(X_train), apply(X_val), apply(X_test), scaler\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, idx_train, idx_val, idx_test = make_windows(df, features, cfg)\n",
    "X_train, X_val, X_test, scaler = scale_windows(X_train, X_val, X_test)\n",
    "\n",
    "print(\"X train/val/test:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"y train lens:\", [arr.shape for arr in y_train])\n",
    "print(\"idx test range:\", int(idx_test[0]), \"->\", int(idx_test[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) \u0410\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 (3 \u0433\u043e\u043b\u043e\u0432\u044b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(seq_len: int, n_features: int) -> Model:\n",
    "    inputs = Input(shape=(seq_len, n_features))\n",
    "\n",
    "    x = Bidirectional(LSTM(96, return_sequences=True))(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(64, return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    shared = Dense(96, activation=\"relu\")(x)\n",
    "\n",
    "    out_delta = Dense(1, name=\"delta\")(shared)\n",
    "    out_direction = Dense(1, activation=\"sigmoid\", name=\"direction\")(shared)\n",
    "    out_quality = Dense(1, activation=\"sigmoid\", name=\"quality\")(shared)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[out_delta, out_direction, out_quality])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss={\n",
    "            \"delta\": tf.keras.losses.Huber(delta=0.5),\n",
    "            \"direction\": \"binary_crossentropy\",\n",
    "            \"quality\": \"binary_crossentropy\",\n",
    "        },\n",
    "        loss_weights={\n",
    "            \"delta\": 0.25,\n",
    "            \"direction\": 0.45,\n",
    "            \"quality\": 0.30,\n",
    "        },\n",
    "        metrics={\n",
    "            \"delta\": [\"mse\"],\n",
    "            \"direction\": [\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")],\n",
    "            \"quality\": [\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")],\n",
    "        },\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(seq_len=X_train.shape[1], n_features=X_train.shape[2])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_direction_accuracy\", mode=\"max\", patience=8, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_direction_accuracy\", mode=\"max\", factor=0.5, patience=3, min_lr=1e-5),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=cfg.epochs,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) \u041f\u043e\u0434\u0431\u043e\u0440 \u0442\u043e\u0440\u0433\u043e\u0432\u044b\u0445 \u043f\u043e\u0440\u043e\u0433\u043e\u0432 \u043d\u0430 validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_trading_thresholds(\n",
    "    y_delta_true: np.ndarray,\n",
    "    p_direction: np.ndarray,\n",
    "    p_quality: np.ndarray,\n",
    "    spread_cost: float,\n",
    "    slippage_cost: float,\n",
    "):\n",
    "    best = {\n",
    "        \"dir_t\": 0.5,\n",
    "        \"qual_t\": 0.5,\n",
    "        \"net_pnl\": -1e9,\n",
    "        \"trades\": 0,\n",
    "    }\n",
    "\n",
    "    dir_grid = np.linspace(0.45, 0.60, 16)\n",
    "    qual_grid = np.linspace(0.50, 0.75, 11)\n",
    "    total_cost = spread_cost + slippage_cost\n",
    "\n",
    "    y = y_delta_true.flatten()\n",
    "    pd = p_direction.flatten()\n",
    "    pq = p_quality.flatten()\n",
    "\n",
    "    for dt in dir_grid:\n",
    "        signal_dir = np.where(pd >= dt, 1, -1)\n",
    "        for qt in qual_grid:\n",
    "            trade_mask = pq >= qt\n",
    "            net_ret = signal_dir * y - total_cost\n",
    "            net_ret = np.where(trade_mask, net_ret, 0.0)\n",
    "\n",
    "            pnl = float(net_ret.sum())\n",
    "            n_trades = int(trade_mask.sum())\n",
    "\n",
    "            if n_trades >= 50 and pnl > best[\"net_pnl\"]:\n",
    "                best = {\n",
    "                    \"dir_t\": float(dt),\n",
    "                    \"qual_t\": float(qt),\n",
    "                    \"net_pnl\": pnl,\n",
    "                    \"trades\": n_trades,\n",
    "                }\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "p_val_delta, p_val_dir, p_val_quality = model.predict(X_val, verbose=0)\n",
    "best = optimize_trading_thresholds(\n",
    "    y_delta_true=y_val[0],\n",
    "    p_direction=p_val_dir,\n",
    "    p_quality=p_val_quality,\n",
    "    spread_cost=cfg.spread_cost,\n",
    "    slippage_cost=cfg.slippage_cost,\n",
    ")\n",
    "\n",
    "best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) \u0424\u0438\u043d\u0430\u043b\u044c\u043d\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043d\u0430 test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_trading(\n",
    "    y_delta_true: np.ndarray,\n",
    "    y_dir_true: np.ndarray,\n",
    "    p_delta: np.ndarray,\n",
    "    p_direction: np.ndarray,\n",
    "    p_quality: np.ndarray,\n",
    "    dir_t: float,\n",
    "    qual_t: float,\n",
    "    spread_cost: float,\n",
    "    slippage_cost: float,\n",
    "):\n",
    "    y_d = y_delta_true.flatten()\n",
    "    y_c = y_dir_true.flatten()\n",
    "\n",
    "    pred_dir = (p_direction.flatten() >= dir_t).astype(int)\n",
    "    trade_mask = p_quality.flatten() >= qual_t\n",
    "\n",
    "    signed_signal = np.where(pred_dir == 1, 1, -1)\n",
    "    gross = signed_signal * y_d\n",
    "    net = gross - (spread_cost + slippage_cost)\n",
    "    net = np.where(trade_mask, net, 0.0)\n",
    "\n",
    "    realized_idx = np.where(trade_mask)[0]\n",
    "    if len(realized_idx) == 0:\n",
    "        return {\n",
    "            \"mse\": mean_squared_error(y_d, p_delta.flatten()),\n",
    "            \"mae\": mean_absolute_error(y_d, p_delta.flatten()),\n",
    "            \"direction_acc_all\": accuracy_score(y_c, pred_dir),\n",
    "            \"direction_f1_all\": f1_score(y_c, pred_dir),\n",
    "            \"trades\": 0,\n",
    "            \"net_pnl\": 0.0,\n",
    "            \"avg_trade\": 0.0,\n",
    "            \"hit_rate_trades\": 0.0,\n",
    "        }\n",
    "\n",
    "    hit_rate_trades = float((net[realized_idx] > 0).mean())\n",
    "\n",
    "    return {\n",
    "        \"mse\": mean_squared_error(y_d, p_delta.flatten()),\n",
    "        \"mae\": mean_absolute_error(y_d, p_delta.flatten()),\n",
    "        \"direction_acc_all\": accuracy_score(y_c, pred_dir),\n",
    "        \"direction_f1_all\": f1_score(y_c, pred_dir),\n",
    "        \"trades\": int(len(realized_idx)),\n",
    "        \"net_pnl\": float(net.sum()),\n",
    "        \"avg_trade\": float(net[realized_idx].mean()),\n",
    "        \"hit_rate_trades\": hit_rate_trades,\n",
    "    }\n",
    "\n",
    "\n",
    "p_test_delta, p_test_dir, p_test_quality = model.predict(X_test, verbose=0)\n",
    "result = evaluate_trading(\n",
    "    y_delta_true=y_test[0],\n",
    "    y_dir_true=y_test[1],\n",
    "    p_delta=p_test_delta,\n",
    "    p_direction=p_test_dir,\n",
    "    p_quality=p_test_quality,\n",
    "    dir_t=best[\"dir_t\"],\n",
    "    qual_t=best[\"qual_t\"],\n",
    "    spread_cost=cfg.spread_cost,\n",
    "    slippage_cost=cfg.slippage_cost,\n",
    ")\n",
    "\n",
    "print(\"=== Thresholds from VAL ===\")\n",
    "print(best)\n",
    "print(\"=== Test Metrics ===\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Backtest \u0441\u043e Stop-Loss \u0438 Take-Profit\n",
    "\n",
    "\u041b\u043e\u0433\u0438\u043a\u0430 \u0441\u0434\u0435\u043b\u043a\u0438 (\u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442 1 \u0431\u0430\u0440):\n",
    "- \u0432\u0445\u043e\u0434 \u043f\u043e `Price_close[t]` \u043d\u0430 \u0431\u0430\u0440\u0435 \u0442\u0430\u0440\u0433\u0435\u0442\u0430,\n",
    "- \u0435\u0441\u043b\u0438 \u0435\u0441\u0442\u044c \u0441\u0438\u0433\u043d\u0430\u043b (`direction` + `quality`), \u043e\u0442\u043a\u0440\u044b\u0432\u0430\u0435\u043c \u043f\u043e\u0437\u0438\u0446\u0438\u044e,\n",
    "- \u0432\u043d\u0443\u0442\u0440\u0438 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u0431\u0430\u0440\u0430 (`t+1`) \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c TP/SL \u043f\u043e `Highest/Lowest`,\n",
    "- \u0435\u0441\u043b\u0438 \u043d\u0435 \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0438 TP/SL, \u0437\u0430\u043a\u0440\u044b\u0442\u0438\u0435 \u043f\u043e `Price_close[t+1]`,\n",
    "- \u0435\u0441\u043b\u0438 \u0432 \u043e\u0434\u043d\u043e\u043c \u0431\u0430\u0440\u0435 \u0438 TP \u0438 SL, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u043a\u043e\u043d\u0441\u0435\u0440\u0432\u0430\u0442\u0438\u0432\u043d\u043e `SL`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_backtest_sl_tp(\n",
    "    df: pd.DataFrame,\n",
    "    idx: np.ndarray,\n",
    "    p_direction: np.ndarray,\n",
    "    p_quality: np.ndarray,\n",
    "    dir_t: float,\n",
    "    qual_t: float,\n",
    "    sl_pct: float = 0.0015,\n",
    "    tp_pct: float = 0.0025,\n",
    "    spread_cost: float = 0.00003,\n",
    "    slippage_cost: float = 0.00001,\n",
    "):\n",
    "    close = df[\"Price_close\"].values\n",
    "    high = df[\"Highest\"].values\n",
    "    low = df[\"Lowest\"].values\n",
    "\n",
    "    pd_sig = p_direction.flatten()\n",
    "    pq_sig = p_quality.flatten()\n",
    "\n",
    "    trades = []\n",
    "    rets = []\n",
    "\n",
    "    for k, t in enumerate(idx):\n",
    "        # \u041d\u0443\u0436\u0435\u043d \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u0431\u0430\u0440 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 TP/SL\n",
    "        if t + 1 >= len(df):\n",
    "            continue\n",
    "\n",
    "        do_trade = pq_sig[k] >= qual_t\n",
    "        if not do_trade:\n",
    "            rets.append(0.0)\n",
    "            continue\n",
    "\n",
    "        side = 1 if pd_sig[k] >= dir_t else -1\n",
    "\n",
    "        entry = close[t]\n",
    "        nxt_high = high[t + 1]\n",
    "        nxt_low = low[t + 1]\n",
    "        nxt_close = close[t + 1]\n",
    "\n",
    "        if side == 1:\n",
    "            tp_price = entry * (1 + tp_pct)\n",
    "            sl_price = entry * (1 - sl_pct)\n",
    "\n",
    "            hit_tp = nxt_high >= tp_price\n",
    "            hit_sl = nxt_low <= sl_price\n",
    "\n",
    "            if hit_tp and hit_sl:\n",
    "                # \u041a\u043e\u043d\u0441\u0435\u0440\u0432\u0430\u0442\u0438\u0432\u043d\u043e: \u0441\u0447\u0438\u0442\u0430\u0435\u043c, \u0447\u0442\u043e SL \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b \u043f\u0435\u0440\u0432\u044b\u043c.\n",
    "                gross_ret = -sl_pct\n",
    "                exit_type = \"SL_both\"\n",
    "            elif hit_sl:\n",
    "                gross_ret = -sl_pct\n",
    "                exit_type = \"SL\"\n",
    "            elif hit_tp:\n",
    "                gross_ret = tp_pct\n",
    "                exit_type = \"TP\"\n",
    "            else:\n",
    "                gross_ret = (nxt_close - entry) / entry\n",
    "                exit_type = \"Close\"\n",
    "        else:\n",
    "            tp_price = entry * (1 - tp_pct)\n",
    "            sl_price = entry * (1 + sl_pct)\n",
    "\n",
    "            hit_tp = nxt_low <= tp_price\n",
    "            hit_sl = nxt_high >= sl_price\n",
    "\n",
    "            if hit_tp and hit_sl:\n",
    "                gross_ret = -sl_pct\n",
    "                exit_type = \"SL_both\"\n",
    "            elif hit_sl:\n",
    "                gross_ret = -sl_pct\n",
    "                exit_type = \"SL\"\n",
    "            elif hit_tp:\n",
    "                gross_ret = tp_pct\n",
    "                exit_type = \"TP\"\n",
    "            else:\n",
    "                gross_ret = (entry - nxt_close) / entry\n",
    "                exit_type = \"Close\"\n",
    "\n",
    "        net_ret = gross_ret - (spread_cost + slippage_cost)\n",
    "        rets.append(net_ret)\n",
    "        trades.append({\n",
    "            \"idx\": int(t),\n",
    "            \"side\": \"LONG\" if side == 1 else \"SHORT\",\n",
    "            \"gross_ret\": float(gross_ret),\n",
    "            \"net_ret\": float(net_ret),\n",
    "            \"exit_type\": exit_type,\n",
    "        })\n",
    "\n",
    "    rets = np.array(rets, dtype=float)\n",
    "    trade_rets = rets[rets != 0.0]\n",
    "\n",
    "    result = {\n",
    "        \"bars\": int(len(rets)),\n",
    "        \"trades\": int(len(trade_rets)),\n",
    "        \"net_pnl\": float(rets.sum()),\n",
    "        \"avg_trade\": float(trade_rets.mean()) if len(trade_rets) else 0.0,\n",
    "        \"hit_rate\": float((trade_rets > 0).mean()) if len(trade_rets) else 0.0,\n",
    "        \"tp_share\": float(sum(t[\"exit_type\"] == \"TP\" for t in trades) / len(trades)) if trades else 0.0,\n",
    "        \"sl_share\": float(sum(t[\"exit_type\"].startswith(\"SL\") for t in trades) / len(trades)) if trades else 0.0,\n",
    "    }\n",
    "\n",
    "    equity = rets.cumsum()\n",
    "    return result, equity, pd.DataFrame(trades)\n",
    "\n",
    "\n",
    "bt_result, bt_equity, bt_trades = run_backtest_sl_tp(\n",
    "    df=df,\n",
    "    idx=idx_test,\n",
    "    p_direction=p_test_dir,\n",
    "    p_quality=p_test_quality,\n",
    "    dir_t=best[\"dir_t\"],\n",
    "    qual_t=best[\"qual_t\"],\n",
    "    sl_pct=0.0015,  # 0.15%\n",
    "    tp_pct=0.0025,  # 0.25%\n",
    "    spread_cost=cfg.spread_cost,\n",
    "    slippage_cost=cfg.slippage_cost,\n",
    ")\n",
    "\n",
    "print(\"=== SL/TP Backtest (Test) ===\")\n",
    "print(bt_result)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(bt_equity)\n",
    "plt.title(\"Equity Curve (SL/TP backtest)\")\n",
    "plt.xlabel(\"Test bars\")\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "bt_trades.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}